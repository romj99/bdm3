services:
  mlflow:
    image: ghcr.io/mlflow/mlflow:v3.1.0
    container_name: mlflow
    restart: always
    ports:
      - "5001:5001"
    environment:
      - MLFLOW_TRACKING_URI=http://0.0.0.0:5001
    command: mlflow server --host 0.0.0.0 --port 5001 --backend-store-uri sqlite:///mlflow.db --default-artifact-root /mlruns
    volumes:
      - ./outputs/mlruns:/mlruns
      - ./data_zones:/data_zones
    env_file:
      - .env
    networks:
      - ml_platform
      
  airflow:
    build:
      context: ./src/airflow
      dockerfile: Dockerfile
    container_name: airflow
    restart: always
    depends_on:
      - mlflow
    ports:
      - "8080:8080"
    volumes:
      - ./src/airflow/dags:/opt/airflow/dags
      - ./src/pipelines:/opt/airflow/plugins
      - ./data_zones:/data_zones
      - ./src/utils:/opt/airflow/utils
    env_file:
      - .env
    environment:
      - AIRFLOW__WEBSERVER__AUTH_BACKEND=airflow.auth.managers.fab.auth_manager.AuthManager
      - AIRFLOW__CORE__SIMPLE_AUTH_MANAGER_ALL_ADMINS=True
      # JAVA_HOME is auto-detected in the Dockerfile - no need to set here
      - SPARK_VERSION=4.0.0
      - PYSPARK_PYTHON=python3
      - PYSPARK_DRIVER_PYTHON=python3
    command: bash -c "source /etc/environment && airflow standalone"
    networks:
      - ml_platform

  streamlit:
    build: ./src/streamlit_ui
    ports:
      - "8501:8501"
    volumes:
      - ./src/streamlit_ui:/app
      - ./src/utils:/app/utils 
      - ./data_zones:/data_zones
    depends_on:
      - airflow
      - mlflow
    env_file:
      - .env
    environment:
      # JAVA_HOME is auto-detected in the Dockerfile - no need to set here
      - SPARK_VERSION=4.0.0
      - PYSPARK_PYTHON=python3
      - PYSPARK_DRIVER_PYTHON=python3
    # Command is handled in Dockerfile CMD with environment loading
    networks:
      - ml_platform

networks:
  ml_platform:
    driver: bridge